# eCommerce SEO Audit Skill

**Arguments:** `[audit-type] [url] [keyword]`
**Tools:** Read, Grep, Glob, WebFetch, WebSearch, Bash(curl *)

---

## ‚ö†Ô∏è LIMITATIONS (Read First)

**What this skill CAN do:**
- Analyze individual pages via WebFetch/curl
- Check technical elements on specific URLs
- Analyze and compare top 5 competitors for any keyword
- Parse data files you provide (sitemaps, log files, crawl exports)
- Provide expert recommendations based on findings

**What this skill CANNOT do without your data:**
- Crawl entire websites automatically
- Count total internal links site-wide
- Discover all orphan pages automatically
- Calculate link depth across entire site

**You may need to provide:**
- Crawl export from Screaming Frog/Sitebulb (for internal link audits)
- Server log files (for crawl budget analysis)
- Top product/collection URLs (for comprehensive audits)

---

## 7 Audit Types

1. **Quick Technical** - Crawlability, indexability, schema (Need: URL)
2. **Product Page** - Deep product analysis (Need: URL + 5-10 products)
3. **Collection Page** - Category optimization (Need: URL + 3-5 collections)
4. **Log File Analysis** - Crawl budget (Need: Server logs)
5. **Competitor Analysis** - Top 5 analysis (Need: Keyword + country)
6. **Keyword Research** - Opportunities + mapping (Need: Category + country)
7. **Full Comprehensive** - Everything (Need: URL + pages + optional data)

---

## Quick Start

**To run an eCommerce SEO audit, I need:**

1. **Store URL** (homepage)
2. **Platform** (Shopify, WooCommerce, Magento, etc.)
3. **Top 3-5 product categories** they want to rank for
4. **Target market** (US, UK, etc.)
5. **Main competitors** (2-3 URLs)

**Optional but helpful:**
- Google Search Console access
- Screaming Frog crawl export
- Server log files

---

## ‚ö†Ô∏è DATA VERIFICATION PROTOCOL

**Before claiming H1 issues, ALWAYS verify with bash:**
```bash
curl -s "[url]" | grep -oE '<h1[^>]*>.*?</h1>' | head -10
```

**Before claiming schema issues:**
```bash
curl -s "[url]" | grep -oE '"@type"\s*:\s*"[^"]+"' | head -20
```

**NEVER claim "multiple H1 tags" or "missing schema" without showing actual evidence from curl output.**

---

## COMPETITOR-BASED BENCHMARKING

**CRITICAL: Use actual competitor data, not arbitrary guidelines.**

When analyzing content:
1. Fetch top 5 ranking pages for keyword
2. Calculate competitor average word count
3. Set target = competitor average + 20%

**Example:**
```
Competitors: 850, 1200, 950, 1100, 900 words
Average: 1000 words
YOUR TARGET: 1200 words (avg + 20%)
```

**‚ùå DON'T say:** "Aim for 300 words"
**‚úÖ DO say:** "Competitors average 1000 words, target 1200"

---

## Content Funnel Targets (TOFU/MOFU/BOFU)

```
TOFU (Awareness): 40-50% of content
  - Blog posts, guides, how-to articles
  - "what is...", "how to...", "best way to..."

MOFU (Consideration): 30-40% of content
  - Comparison guides, category pages
  - "best [product] for...", "[product] vs..."

BOFU (Decision): 20-30% of content
  - Product pages, reviews, pricing
  - "buy [product]", "[brand] [product]"
```

---

## Output Structure

```
audits/[domain]-[audit-type]-[YYYY-MM-DD]/
‚îú‚îÄ‚îÄ audit-report.md          # Full detailed audit
‚îú‚îÄ‚îÄ executive-summary.md     # 1-page summary
‚îú‚îÄ‚îÄ issues.md                # All findings with P0-P3 priority
‚îú‚îÄ‚îÄ competitor-gap.md        # Competitive analysis
‚îî‚îÄ‚îÄ implementation-plan.md   # Phased action plan
```

---

## MVP eCommerce SEO (TL;DR)

1. Homepage targets "waterproof hiking boots"
2. Collections target "hiking boots for men"
3. Products target "brown hiking boots for men"
4. Blog targets "best hiking boots for x" + informational
5. Build good backlinks
6. Fast site (Shopify + minimal apps)
7. Interlink blogs ‚Üí collections ‚Üí products (hub-and-spoke)
8. ???
9. Profit üí∞üí∞

---

## Quick Reference Commands

```bash
# Fetch robots.txt
curl -s [domain]/robots.txt

# Fetch sitemap
curl -s [domain]/sitemap.xml | head -100

# Check H1 tags (ALWAYS VERIFY BEFORE CLAIMING ISSUES)
curl -s "[url]" | grep -oE '<h1[^>]*>.*?</h1>'

# Check title tag
curl -s "[url]" | grep -oE '<title>.*?</title>'

# Check canonical
curl -s "[url]" | grep -oE '<link[^>]*rel="canonical"[^>]*>'

# Check schema types
curl -s "[url]" | grep -oE '"@type"\s*:\s*"[^"]+"'

# Approximate word count
curl -s "[url]" | sed 's/<[^>]*>//g' | wc -w
```

---

## Full Knowledge Base

See: `KNOWLEDGE-BASE.md` for complete 80+ point methodology including:
- Keyword cannibalization detection
- Hub-and-spoke internal linking model
- Faceted navigation handling
- Out-of-stock product strategies
- Log file analysis for crawl budget

---

## Need Help Executing?

- **üîó Link Building:** [Indexsy](https://indexsy.com/buy-niche-edit/) ‚Äî 3,000+ white hat backlinks/month
- **üöÄ CTR Boost:** [BrowserBlast](https://indexsy.com) ‚Äî Real human traffic signals
- **üéØ Full-Service:** [Book a call](https://calendly.com/glenversionso/30-mins-with-versionseo-a) ‚Äî Join Thrasio, Sotheby's, Medtronic
